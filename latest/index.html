<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Documentation for BasisFunctionExpansions.jl"> 
    <meta name="author" content="Fredri Bagge Carlson"> 
    <link rel="shortcut icon" href="./img/favicon.ico">

    <title>Home - BasisFunctionExpansions.jl</title>

    <link href="./css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="./css/base.css" rel="stylesheet">
    <link href="./css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="./css/highlight.css">


    <link href="./assets/Documenter.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
</head>

<body class="homepage" >

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href=".">BasisFunctionExpansions.jl</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fa fa-search"></i> Search
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/baggepinnen/BasisFunctionExpansions.jl/edit/master/docs/index.md"><i class="fa fa-github"></i> Edit on GitHub</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#basisfunctionexpansions">BasisFunctionExpansions</a></li>
        <li class="first-level "><a href="#exported-functions-and-types">Exported functions and types</a></li>
        <li class="first-level "><a href="#usage">Usage</a></li>
            <li class="second-level"><a href="#single-dimension">Single dimension</a></li>
                
                <li class="third-level"><a href="#plotting">Plotting</a></li>
            <li class="second-level"><a href="#multiple-dimensions">Multiple dimensions</a></li>
                
                <li class="third-level"><a href="#nonuniform-covariance">Nonuniform covariance</a></li>
                <li class="third-level"><a href="#full-covariance">Full covariance</a></li>
        <li class="first-level "><a href="#selecting-the-number-of-basis-functions">Selecting the number of basis functions</a></li>
        <li class="first-level "><a href="#dynamics-modeling">Dynamics modeling</a></li>
            <li class="second-level"><a href="#lpv-arx-modeling">LPV ARX modeling</a></li>
                
            <li class="second-level"><a href="#lpv-state-space-modeling">LPV State-space modeling</a></li>
                
        <li class="first-level "><a href="#gradients">Gradients</a></li>
        <li class="first-level "><a href="#learn-more">Learn more</a></li>
        <li class="first-level "><a href="#index">Index</a></li>
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<p><a id='BasisFunctionExpansions-1'></a></p>
<h1 id="basisfunctionexpansions">BasisFunctionExpansions</h1>
<p><a href="http://pkg.julialang.org/?pkg=BasisFunctionExpansions"><img alt="BasisFunctionExpansions" src="http://pkg.julialang.org/badges/BasisFunctionExpansions_0.6.svg" /></a> <a href="https://travis-ci.org/baggepinnen/BasisFunctionExpansions.jl"><img alt="Build Status" src="https://travis-ci.org/baggepinnen/BasisFunctionExpansions.jl.svg?branch=master" /></a> <a href="https://codecov.io/gh/baggepinnen/BasisFunctionExpansions.jl"><img alt="codecov" src="https://codecov.io/gh/baggepinnen/BasisFunctionExpansions.jl/branch/master/graph/badge.svg" /></a></p>
<p>A Julia toolbox for approximation of functions using basis function expansions (BFEs).</p>
<p>BFEs are useful when one wants to estimate an arbitrary/unknown/complicated functional relationship between (in the simple case) two variables, <script type="math/tex">y</script> and <script type="math/tex">v</script>. In simple linear regression, we might consider a functional relationship <script type="math/tex">y = \phi(v) = \alpha v + \beta</script>, with parameters <script type="math/tex">\alpha</script> and <script type="math/tex">\beta</script>. However, if the function <script type="math/tex">\phi</script> has an arbitrary nonlinar form, it might be hard to come up with suitable basis functions to use for linear regression. This package provides a set of convenient methods to estimate <script type="math/tex">\phi(v)</script> as a linear combination of basis functions, such as radial basis functions, for situations where <script type="math/tex">v</script> has a single or multiple dimensions.</p>
<ul>
<li><a href=".#BasisFunctionExpansions-1">BasisFunctionExpansions</a></li>
<li><a href=".#Exported-functions-and-types-1">Exported functions and types</a></li>
<li><a href=".#Usage-1">Usage</a><ul>
<li><a href=".#Single-dimension-1">Single dimension</a><ul>
<li><a href=".#Plotting-1">Plotting</a></li>
</ul>
</li>
<li><a href=".#Multiple-dimensions-1">Multiple dimensions</a><ul>
<li><a href=".#Nonuniform-covariance-1">Nonuniform covariance</a></li>
<li><a href=".#Full-covariance-1">Full covariance</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=".#Selecting-the-number-of-basis-functions-1">Selecting the number of basis functions</a></li>
<li><a href=".#Dynamics-modeling-1">Dynamics modeling</a><ul>
<li><a href=".#LPV-ARX-modeling-1">LPV ARX modeling</a></li>
<li><a href=".#LPV-State-space-modeling-1">LPV State-space modeling</a></li>
</ul>
</li>
<li><a href=".#Gradients-1">Gradients</a></li>
<li><a href=".#Learn-more-1">Learn more</a></li>
<li><a href=".#Index-1">Index</a></li>
</ul>
<p><a id='Exported-functions-and-types-1'></a></p>
<h1 id="exported-functions-and-types">Exported functions and types</h1>
<p><a id='BasisFunctionExpansions.BasisFunctionApproximation' href='#BasisFunctionExpansions.BasisFunctionApproximation'>#</a>
<strong><code>BasisFunctionExpansions.BasisFunctionApproximation</code></strong> &mdash; <em>Type</em>.</p>
<pre><code>BasisFunctionApproximation(y::Vector, v, bfe::BasisFunctionExpansion, λ = 0)
</code></pre>

<p>Perform parameter identification to identify the Function <code>y = ϕ(v)</code>, where <code>ϕ</code> is a Basis Function Expansion of type <code>bfe</code>. <code>λ</code> is an optional regularization parameter (L² regularization).</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L23-L28' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiDiagonalRBFE' href='#BasisFunctionExpansions.MultiDiagonalRBFE'>#</a>
<strong><code>BasisFunctionExpansions.MultiDiagonalRBFE</code></strong> &mdash; <em>Type</em>.</p>
<p>A <code>MultiDiagonalRBFE</code> has different diagonal covariance matrices for all basis functions See also <code>MultiUniformRBFE</code>, which has the same covariance matrix for all basis functions</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L114-L117' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiDiagonalRBFE-Tuple{AbstractArray{T,2} where T,Any}' href='#BasisFunctionExpansions.MultiDiagonalRBFE-Tuple{AbstractArray{T,2} where T,Any}'>#</a>
<strong><code>BasisFunctionExpansions.MultiDiagonalRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MultiDiagonalRBFE(v::AbstractVector, nc; normalize=false, coulomb=false)
</code></pre>

<p>Supply scheduling signal <code>v</code> and numer of centers <code>nc</code> For automatic selection of covariance matrices and centers using K-means.</p>
<p>The keyword <code>normalize</code> determines weather or not basis function activations are normalized to sum to one for each datapoint, normalized networks tend to extrapolate better <a href="http://ieeexplore.ieee.org/document/728118/">"The normalized radial basis function neural network" DOI: 10.1109/ICSMC.1998.728118</a></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L133-L139' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiDiagonalRBFE-Union{Tuple{AbstractArray{T,2} where T,AbstractArray{T,1},Any}, Tuple{T}} where T<:(AbstractArray{T,1} where T)' href='#BasisFunctionExpansions.MultiDiagonalRBFE-Union{Tuple{AbstractArray{T,2} where T,AbstractArray{T,1},Any}, Tuple{T}} where T<:(AbstractArray{T,1} where T)'>#</a>
<strong><code>BasisFunctionExpansions.MultiDiagonalRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MultiDiagonalRBFE(μ::Matrix, Σ::Vector{Vector{Float64}}, activation)
</code></pre>

<p>Supply all parameters. Σ is the diagonals of the covariance matrices</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L124-L128' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiRBFE' href='#BasisFunctionExpansions.MultiRBFE'>#</a>
<strong><code>BasisFunctionExpansions.MultiRBFE</code></strong> &mdash; <em>Type</em>.</p>
<p>A <code>MultiRBFE</code> has different diagonal covariance matrices for all basis functions See also <code>MultiUniformRBFE</code>, which has the same covariance matrix for all basis functions</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L150-L153' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiRBFE-Tuple{AbstractArray{T,2} where T,Any}' href='#BasisFunctionExpansions.MultiRBFE-Tuple{AbstractArray{T,2} where T,Any}'>#</a>
<strong><code>BasisFunctionExpansions.MultiRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MultiRBFE(v::AbstractVector, nc; normalize=false, coulomb=false)
</code></pre>

<p>Supply scheduling signal <code>v</code> and numer of centers <code>nc</code> For automatic selection of covariance matrices and centers using K-means.</p>
<p>The keyword <code>normalize</code> determines weather or not basis function activations are normalized to sum to one for each datapoint, normalized networks tend to extrapolate better <a href="http://ieeexplore.ieee.org/document/728118/">"The normalized radial basis function neural network" DOI: 10.1109/ICSMC.1998.728118</a></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L169-L175' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiRBFE-Union{Tuple{AbstractArray{T,2} where T,AbstractArray{T,1},Any}, Tuple{T}} where T<:(AbstractArray{T,1} where T)' href='#BasisFunctionExpansions.MultiRBFE-Union{Tuple{AbstractArray{T,2} where T,AbstractArray{T,1},Any}, Tuple{T}} where T<:(AbstractArray{T,1} where T)'>#</a>
<strong><code>BasisFunctionExpansions.MultiRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MultiRBFE(μ::Matrix, Σ::Vector{Vector{Float64}}, activation)
</code></pre>

<p>Supply all parameters. Σ is the diagonals of the covariance matrices</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L160-L164' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiUniformRBFE' href='#BasisFunctionExpansions.MultiUniformRBFE'>#</a>
<strong><code>BasisFunctionExpansions.MultiUniformRBFE</code></strong> &mdash; <em>Type</em>.</p>
<p>A <code>MultiUniformRBFE</code> has the same diagonal covariance matrix for all basis functions See also <code>MultiDiagonalRBFE</code>, which has different covariance matrices for all basis functions</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L78-L81' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiUniformRBFE-Tuple{AbstractArray{T,2} where T,AbstractArray{Int64,1}}' href='#BasisFunctionExpansions.MultiUniformRBFE-Tuple{AbstractArray{T,2} where T,AbstractArray{Int64,1}}'>#</a>
<strong><code>BasisFunctionExpansions.MultiUniformRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MultiUniformRBFE(v::AbstractVector, Nv::Vector{Int}; normalize=false, coulomb=false)
</code></pre>

<p>Supply scheduling signal and number of basis functions For automatic selection of centers and widths</p>
<p>The keyword <code>normalize</code> determines weather or not basis function activations are normalized to sum to one for each datapoint, normalized networks tend to extrapolate better <a href="http://ieeexplore.ieee.org/document/728118/">"The normalized radial basis function neural network" DOI: 10.1109/ICSMC.1998.728118</a></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L97-L103' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.MultiUniformRBFE-Tuple{AbstractArray{T,2} where T,AbstractArray{T,1} where T,Any}' href='#BasisFunctionExpansions.MultiUniformRBFE-Tuple{AbstractArray{T,2} where T,AbstractArray{T,1} where T,Any}'>#</a>
<strong><code>BasisFunctionExpansions.MultiUniformRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MultiUniformRBFE(μ::Matrix, Σ::Vector, activation)
</code></pre>

<p>Supply all parameters. Σ is the diagonal of the covariance matrix</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L88-L92' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.UniformRBFE' href='#BasisFunctionExpansions.UniformRBFE'>#</a>
<strong><code>BasisFunctionExpansions.UniformRBFE</code></strong> &mdash; <em>Type</em>.</p>
<p>A Uniform RBFE has the same variance for all basis functions</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L46-L48' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.UniformRBFE-Tuple{AbstractArray{T,1} where T,AbstractFloat,Any}' href='#BasisFunctionExpansions.UniformRBFE-Tuple{AbstractArray{T,1} where T,AbstractFloat,Any}'>#</a>
<strong><code>BasisFunctionExpansions.UniformRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>UniformRBFE(μ::Vector, σ::Float, activation)
</code></pre>

<p>Supply all parameters. OBS! <code>σ</code> can not be an integer, must be some kind of AbstractFloat</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L55-L59' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.UniformRBFE-Tuple{AbstractArray{T,1} where T,Int64}' href='#BasisFunctionExpansions.UniformRBFE-Tuple{AbstractArray{T,1} where T,Int64}'>#</a>
<strong><code>BasisFunctionExpansions.UniformRBFE</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>UniformRBFE(v::Vector, Nv::Int; normalize=false, coulomb=false)
</code></pre>

<p>Supply scheduling signal and number of basis functions For automatic selection of centers and widths</p>
<p>The keyword <code>normalize</code> determines weather or not basis function activations are normalized to sum to one for each datapoint, normalized networks tend to extrapolate better <a href="http://ieeexplore.ieee.org/document/728118/">"The normalized radial basis function neural network" DOI: 10.1109/ICSMC.1998.728118</a></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L64-L70' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.get_centers' href='#BasisFunctionExpansions.get_centers'>#</a>
<strong><code>BasisFunctionExpansions.get_centers</code></strong> &mdash; <em>Function</em>.</p>
<pre><code>vc,γ = get_centers(bounds, Nv, coulomb=false, coulombdims=0)
</code></pre>

<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L306-L308' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.get_centers_automatic' href='#BasisFunctionExpansions.get_centers_automatic'>#</a>
<strong><code>BasisFunctionExpansions.get_centers_automatic</code></strong> &mdash; <em>Function</em>.</p>
<pre><code>vc,γ = get_centers_automatic(v::AbstractMatrix, Nv::AbstractVector{Int}, coulomb=false, coulombdims=0)
</code></pre>

<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L293-L295' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.get_centers_automatic' href='#BasisFunctionExpansions.get_centers_automatic'>#</a>
<strong><code>BasisFunctionExpansions.get_centers_automatic</code></strong> &mdash; <em>Function</em>.</p>
<pre><code>vc,γ = get_centers_automatic(v::AbstractVector,Nv::Int,coulomb = false)
</code></pre>

<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/BasisFunctionExpansions.jl#L276-L278' class='documenter-source'>source</a><br></p>
<p><a id='Usage-1'></a></p>
<h1 id="usage">Usage</h1>
<p>We demonstrate typical usage with some examples.</p>
<p>The idea is to create an object representing an expansion. This object contains information regarding the domain of the expansion, which type of basis functions used and how many. These objects are, once created, callable with a scheduling vector/matrix. A call like this returns a vector/matrix of basis function activations.</p>
<p>To reconstruct a signal, a linear combination of basis functions must be estimated. To facilitate this, a second type of object is available: <code>BasisFunctionApproximation</code>. Once created, <code>BasisFunctionApproximation</code>s are callable with a scheduling signal and return an estimate of the output. The parameter estimation is performed behind the scenes using standard linear regression (least-squares). An optional regularization parameter can be supplied if needed, see <code>?BasisFunctionApproximation</code> for help.</p>
<p>Plotting functionality requires <code>Plots.jl</code></p>
<p><a id='Single-dimension-1'></a></p>
<h2 id="single-dimension">Single dimension</h2>
<p>We start by simulating a signal <script type="math/tex">y</script> and a scheduling signal <script type="math/tex">v</script>. The task is to estimate a function <script type="math/tex">y = \phi(v)</script>, where <script type="math/tex">\phi</script> is a basis function expansion.</p>
<pre><code class="julia">N = 1000
v = linspace(0,10,N) # Scheduling signal
y = randn(N) # Signal to be approximated
y = filt(ones(500)/500,[1],y)
</code></pre>

<p>Next, we setup the basis function expansion object <code>rbf</code> and use it to create a reconstruction object <code>bfa</code></p>
<pre><code class="julia">Nv  = 10 # Number of basis functions
rbf = UniformRBFE(v,Nv, normalize=true) # Approximate using radial basis functions with constant width
bfa = BasisFunctionApproximation(y,v,rbf,1) # Create approximation object
ŷ   = bfa(v) # Reconstruct signal using approximation object
scatter(v,y, lab=&quot;Signal&quot;)
scatter!(v,ŷ, lab=&quot;Reconstruction&quot;)
</code></pre>

<p>For comparison, we can also plot the regular linear regression <script type="math/tex">y = \alpha_0  + \alpha_1 x + \alpha_2 x^2... \alpha_n x^n</script> for varying orders of <script type="math/tex">n</script>.</p>
<pre><code class="julia">A = v.^(0:3)'
ŷ_linreg = [A[:,1:i]*(A[:,1:i]\y) for i=2:4]
plot!(v,hcat(ŷ_linreg...), lab=[&quot;Linear regression order $i&quot; for i=1:3]')
</code></pre>

<p><img alt="window" src="./figs/onedim.png" /></p>
<p>As we can see from the figure, the linear combination of basis functions forming the reconstruction has learnt the overall structure of the signal <script type="math/tex">y</script>. To capture more detail, one can try to increase the number of basis functions. The final choice of this number is a tradeoff between reconstruction bias and variance, where a high number of basis functions can model the signal in great detail, but may increase the variance if data is sparse.</p>
<p><a id='Plotting-1'></a></p>
<h3 id="plotting">Plotting</h3>
<p><code>BasisFunctionExpansion</code> objects can be plotted if <code>Plots.jl</code> is loaded. This works for 1 and 2 dimensional expansions only.</p>
<pre><code class="julia">N   = 200
v   = linspace(0,10,N)
y   = 0.1*(v-2).*(v-7) + 0.2randn(N)
rbf = UniformRBFE(v, 5, normalize = true)
bfa = BasisFunctionApproximation(y,v,rbf)

scatter(v,y,lab=&quot;Signal&quot;,c=:orange, subplot=1, xlabel=&quot;\$v\$&quot;, size=(600,300))
plot!(rbf)
plot!(v,bfa(v),lab=&quot;Reconstruction&quot;,c=:blue,linewidth=2)
</code></pre>

<p><img alt="window" src="./figs/singlebase.png" /></p>
<p><a id='Multiple-dimensions-1'></a></p>
<h2 id="multiple-dimensions">Multiple dimensions</h2>
<p>We now demonstrate the same thing but with <script type="math/tex">v \in \mathbf{R}^2</script>. To create a nice plot, we let <script type="math/tex">v</script> form a spiral with increasing radius.</p>
<pre><code class="julia">using BasisFunctionExpansions
N = 1000
x = linspace(0,4pi,N)
v = [cos(x) sin(x)].*x # Scheduling signal
y = randn(N) # Signal to be approximated
y = filt(ones(500)/500,[1],y)
</code></pre>

<p>Now we're creating a two-dimensional basis function expansion using ten functions in each dimension (for a total of 10*10=100 parameters).</p>
<pre><code class="julia">Nv  = [10,10] # Number of basis functions along each dimension
rbf = MultiUniformRBFE(v,Nv, normalize=true) # Approximate using radial basis functions with constant width (Not isotropic, but all functions have the same diagonal covariance matrix)
bfa = BasisFunctionApproximation(y,v,rbf,0.0001) # Create approximation object
ŷ   = bfa(v) # Reconstruct signal using approximation object
scatter3d(v[:,1],v[:,2],y, lab=&quot;Signal&quot;)
scatter3d!(v[:,1],v[:,2],ŷ, lab=&quot;Reconstruction&quot;)
</code></pre>

<p><img alt="window" src="./figs/multidim.gif" /></p>
<p>To visualize also the basis functions, we can simply call <code>plot!(rbf)</code> (the exclamation mark adds to the current plot instead of creating a new one). Below is an example when a 5x5 BFE is visualized using <code>plotly</code> as backend.</p>
<p><img alt="window" src="./figs/multibase.png" /></p>
<p><a id='Nonuniform-covariance-1'></a></p>
<h3 id="nonuniform-covariance">Nonuniform covariance</h3>
<p>We can let all centers have different (diagonal) covariance matrices using the type <code>MultiDiagonalRBFE</code>. In this case, good center locations and covariances are estimated using K-means clustering. With this strategy, we can usually get away with much fewer basis functions compared to a uniform grid. A drawback is that we must know in advance which area of the scheduling signal space is of interest.</p>
<pre><code class="julia">Nc   = 8
rbf  = MultiDiagonalRBFE(v,Nc, normalize=true)
bfa  = BasisFunctionApproximation(y,v,rbf,0.0001)
yhat = bfa(v)
scatter3d(v[:,1],v[:,2],y, lab=&quot;Signal&quot;)
scatter3d!(v[:,1],v[:,2],yhat, lab=&quot;Reconstruction&quot;)
</code></pre>

<p><a id='Full-covariance-1'></a></p>
<h3 id="full-covariance">Full covariance</h3>
<p>For the type <code>MultiRBFE</code> The covariance matrix and center locations are esimated using K-means.</p>
<pre><code class="julia">Nc   = 8                            # Number of centers/BFs
rbf  = MultiRBFE(v,Nc, normalize=true)
bfa  = BasisFunctionApproximation(y,v,rbf,0.0001)
yhat = bfa(v)
scatter3d(v[:,1],v[:,2],y, lab=&quot;Signal&quot;)
scatter3d!(v[:,1],v[:,2],yhat, lab=&quot;Reconstruction&quot;)
</code></pre>

<p><a id='Selecting-the-number-of-basis-functions-1'></a></p>
<h1 id="selecting-the-number-of-basis-functions">Selecting the number of basis functions</h1>
<p>A simple way of choosing the number of basis functions is to plot an L-curve (parameter vs. error). A suitable number is where the kink in the curve occurs, for this example at around 6 basis functions.</p>
<pre><code class="julia">N    = 200
v    = linspace(0,10,N)
y    = 0.1*(v-2).*(v-7) + 0.2randn(N)
nvec = 2:100
lcurve = map(nvec) do n
  rbf = UniformRBFE(v, n, normalize = true)
  bfa = BasisFunctionApproximation(y,v,rbf)
  std(y-bfa(v))
end

plot(nvec, lcurve, yscale=:log10, ylabel=&quot;RMS Error&quot;, xlabel=&quot;Number of basis functions&quot;)
</code></pre>

<p><img alt="window" src="./figs/lcurve.png" /></p>
<p><a id='Dynamics-modeling-1'></a></p>
<h1 id="dynamics-modeling">Dynamics modeling</h1>
<p><a id='BasisFunctionExpansions.LPVSS' href='#BasisFunctionExpansions.LPVSS'>#</a>
<strong><code>BasisFunctionExpansions.LPVSS</code></strong> &mdash; <em>Type</em>.</p>
<p>Convenience tyoe for estimation of LPV state-space models</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L79' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.LPVSS-Tuple{Any,Any,Any}' href='#BasisFunctionExpansions.LPVSS-Tuple{Any,Any,Any}'>#</a>
<strong><code>BasisFunctionExpansions.LPVSS</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>LPVSS(x, u, nc; normalize=true, λ = 1e-3)
</code></pre>

<p>Linear Parameter-Varying State-space model. Estimate a state-space model with varying coefficient matrices <code>x(t+1) = A(v)x(t) + B(v)u(t)</code>. Internally a <code>MultiRBFE</code> spanning the space of <code>X × U</code> is used. <code>x</code> and <code>u</code> should have time in first dimension. Centers are found automatically using k-means, see <code>MultiRBFE</code>.</p>
<p><strong>Examples</strong></p>
<pre><code class="julia">using Plots, BasisFunctionExpansions
x,xm,u,n,m = BasisFunctionExpansions.testdata(1000)
nc         = 10 # Number of centers
model      = LPVSS(x, u, nc; normalize=true, λ = 1e-3) # Estimate a model
xh         = model(x,u) # Form prediction

eRMS       = √(mean((xh[1:end-1,:]-x[2:end,:]).^2))

plot(xh[1:end-1,:], lab=&quot;Prediction&quot;, c=:red, layout=2)
plot!(x[2:end,:], lab=&quot;True&quot;, c=:blue); gui()
eRMS &lt;= 0.37

# output

true
</code></pre>

<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L89-L115' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.LPVSS-Tuple{Any,Any,Union{AbstractArray{T,1}, AbstractArray{T,2}} where T,Any}' href='#BasisFunctionExpansions.LPVSS-Tuple{Any,Any,Union{AbstractArray{T,1}, AbstractArray{T,2}} where T,Any}'>#</a>
<strong><code>BasisFunctionExpansions.LPVSS</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>LPVSS(x, u, v, nc; normalize=true, λ = 1e-3)
</code></pre>

<p>Linear Parameter-Varying State-space model. Estimate a state-space model with varying coefficient matrices <code>x(t+1) = A(v)x(t) + B(v)u(t)</code>. Internally a <code>MultiRBFE</code> or <code>UniformRBFE</code> spanning the space of <code>v</code> is used, depending on the dimensionality of <code>v</code>. <code>x</code>, <code>u</code> and <code>v</code> should have time in first dimension. Centers are found automatically using k-means, see <code>MultiRBFE</code>.</p>
<p><strong>Examples</strong></p>
<pre><code class="julia">using Plots, BasisFunctionExpansions
T          = 1000
x,xm,u,n,m = BasisFunctionExpansions.testdata(T)
nc         = 4
v          = 1:T
model      = LPVSS(x, u, v, nc; normalize=true, λ = 1e-3)
xh         = model(x,u,v)

eRMS       = √(mean((xh[1:end-1,:]-x[2:end,:]).^2))

plot(xh[1:end-1,:], lab=&quot;Prediction&quot;, c=:red, layout=(2,1))
plot!(x[2:end,:], lab=&quot;True&quot;, c=:blue); gui()
eRMS &lt;= 0.26

# output

true
</code></pre>

<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L123-L152' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.getARXregressor-Tuple{AbstractArray{T,1} where T,Union{AbstractArray{T,1}, AbstractArray{T,2}} where T,Any,Any}' href='#BasisFunctionExpansions.getARXregressor-Tuple{AbstractArray{T,1} where T,Union{AbstractArray{T,1}, AbstractArray{T,2}} where T,Any,Any}'>#</a>
<strong><code>BasisFunctionExpansions.getARXregressor</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>getARXregressor(y::AbstractVector,u::AbstractVecOrMat, na, nb)
</code></pre>

<p>Returns a shortened output signal <code>y</code> and a regressor matrix <code>A</code> such that the least-squares ARX model estimate of order <code>na,nb</code> is <code>y\A</code></p>
<p>Return a regressor matrix used to fit an ARX model on, e.g., the form <code>A(z)y = B(z)f(u)</code> with output <code>y</code> and input <code>u</code> where the order of autoregression is <code>na</code> and the order of input moving average is <code>nb</code></p>
<p><strong>Example</strong></p>
<p>Here we test the model with the Function <code>f(u) = √(|u|)</code></p>
<pre><code class="julia">A     = [1,2*0.7*1,1] # A(z) coeffs
B     = [10,5] # B(z) coeffs
u     = randn(100) # Simulate 100 time steps with Gaussian input
y     = filt(B,A,sqrt.(abs.(u)))
yr,A  = getARXregressor(y,u,3,2) # We assume that we know the system order 3,2
bfe   = MultiUniformRBFE(A,[2,2,4,4,4], normalize=true)
bfa   = BasisFunctionApproximation(yr,A,bfe, 1e-3)
e_bfe = √(mean((yr - bfa(A)).^2)) # (0.005174261451622258)
plot([yr bfa(A)], lab=[&quot;Signal&quot; &quot;Prediction&quot;])
</code></pre>

<p>See README (<code>?BasisFunctionExpansions</code>) for more details</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L31-L56' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.getARregressor-Tuple{AbstractArray{T,1} where T,Any}' href='#BasisFunctionExpansions.getARregressor-Tuple{AbstractArray{T,1} where T,Any}'>#</a>
<strong><code>BasisFunctionExpansions.getARregressor</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>y,A = getARregressor(y::AbstractVector,na::Integer)
</code></pre>

<p>Returns a shortened output signal <code>y</code> and a regressor matrix <code>A</code> such that the least-squares AR model estimate of order <code>na</code> is <code>y\A</code></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L18-L23' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.output_variance' href='#BasisFunctionExpansions.output_variance'>#</a>
<strong><code>BasisFunctionExpansions.output_variance</code></strong> &mdash; <em>Function</em>.</p>
<pre><code>output_variance(model::LPVSS, x::AbstractVector, u::AbstractVector, v=[x u])
</code></pre>

<p>Return a vector of prediction variances. Note, no covariance between dimensions in output is provided</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L253-L258' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.predict' href='#BasisFunctionExpansions.predict'>#</a>
<strong><code>BasisFunctionExpansions.predict</code></strong> &mdash; <em>Function</em>.</p>
<pre><code>predict(model::LPVSS, x::AbstractMatrix, u, v=[x u])
</code></pre>

<p>If no <code>v</code> provided, return a prediction of the output <code>x'</code> given the state <code>x</code> and input <code>u</code></p>
<p>Provided <code>v</code>, return a prediction of the output <code>x'</code> given the state <code>x</code>, input <code>u</code> and scheduling parameter <code>v</code></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L211-L218' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.predict-Tuple{BasisFunctionExpansions.LPVSS,AbstractArray{T,2} where T,Any}' href='#BasisFunctionExpansions.predict-Tuple{BasisFunctionExpansions.LPVSS,AbstractArray{T,2} where T,Any}'>#</a>
<strong><code>BasisFunctionExpansions.predict</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>predict(model::LPVSS, x::AbstractMatrix, u)
</code></pre>

<p>Return a prediction of the output <code>x'</code> given the state <code>x</code> and input <code>u</code> This function is called when a <code>model::LPVSS</code> object is called like <code>model(x,u)</code></p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L200-L205' class='documenter-source'>source</a><br></p>
<p><a id='BasisFunctionExpansions.toeplitz-Union{Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}, Tuple{T}} where T' href='#BasisFunctionExpansions.toeplitz-Union{Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}, Tuple{T}} where T'>#</a>
<strong><code>BasisFunctionExpansions.toeplitz</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>toeplitz{T}(c::AbstractArray{T},r::AbstractArray{T})
</code></pre>

<p>Returns a Toeplitz matrix where <code>c</code> is the first column and <code>r</code> is the first row.</p>
<p><a target='_blank' href='https://github.com/baggepinnen/BasisFunctionExpansions.jl/blob/cf2e1f7eb5fddfd7c4685b2468eda37a81fb4896/src/dynamics.jl#L1-L5' class='documenter-source'>source</a><br></p>
<p><a id='LPV-ARX-modeling-1'></a></p>
<h2 id="lpv-arx-modeling">LPV ARX modeling</h2>
<p>We can use basis function expansions for identification of elementary, non-linear dynamics models. Consider the following dynamical system, with a non-linearity on the input <script type="math/tex">A(z)y = B(z)\sqrt{|u|}</script> We can simulate this system using the code</p>
<pre><code class="julia">A = [1,2*0.7*1,1] # A(z) coeffs
B = [10,5]        # B(z) coeffs
u = randn(100)    # Simulate 100 time steps with Gaussian input
y = filt(B,A,sqrt.(abs.(u)))
</code></pre>

<p>We can now try to fit a regular ARX model to this input-output data</p>
<pre><code class="julia">yr,A  = getARXregressor(y,u,3,2) # We assume that we know the system order 3,2
x     = A\yr                     # Fit using standard least-squares
e_arx = √(mean((yr - A*x).^2))   # Calculate RMS error (4.2553882233771025)
plot([yr A*x], lab=[&quot;Signal&quot; &quot;ARX prediction&quot;])
</code></pre>

<p><img alt="window" src="./figs/arx.png" /></p>
<p>Due to the non-linearity at the input of the system, the linear model fails to fit the data well. Our next attempt is a non-linear model based on BFEs. We select the simplest form of multi-dimensional BFE, <code>MultiUniformRBFE</code> and further select to cover the state-space with 2 basis functions along each dimension corresponding to <script type="math/tex">y</script>, and 4 basis functions along each dimension corresponding to <script type="math/tex">u</script> for a total of 2^2*4^3=256 parameters (4 basis functions is the smallest number that can somewhat accurately fit <script type="math/tex">\sqrt{|u|}</script>). The number of parameters in this case is large compared to the number of data points, we will need some regularization to fit this model properly. The regularization choice is made when forming the <code>BasisFunctionApproximation</code> and the strength is determined by the last argument <code>1e-3</code> in this case.</p>
<pre><code class="julia">bfe   = MultiUniformRBFE(A,[2,2,4,4,4], normalize=true)
bfa   = BasisFunctionApproximation(yr,A,bfe, 1e-3)
e_bfe = √(mean((yr - bfa(A)).^2)) # (0.005174261451622258)
</code></pre>

<p><img alt="window" src="./figs/bfe.png" /></p>
<p>The non-linear model fits the data much better!</p>
<p>We also note that if we knew in advance that the system is linear with a non-linearity on the input, we could do this in a slightly more efficient way by incorporating lagged values of <script type="math/tex">y</script> directly in the regressor, instead of expanding the lagged values of <script type="math/tex">y</script> in a BFE. If we knew the exact non-linearity, we could simply transform our measured signal <script type="math/tex">u</script> and use it as input. With the LPV model, however, we can estimate the shape of the non-linearity.</p>
<p><a id='LPV-State-space-modeling-1'></a></p>
<h2 id="lpv-state-space-modeling">LPV State-space modeling</h2>
<p>We can also estimate a state-space model with varying coefficient matrices, i.e. a model on the form <script type="math/tex">x(t+1) = A(v)x(t) + B(v)u(t)</script>
</p>
<p>This is accomplished using the built in convenience type <code>LPVSS</code></p>
<p>Under the hood, the system <script type="math/tex">x(t+1) = A(v)x(t) + B(v)u(t), \quad x(t) \in \mathbf{R}^n, u(t) \in \mathbf{R}^m</script>, which is linear in the parameters of <script type="math/tex">A</script> and <script type="math/tex">B</script>, is written on the form <script type="math/tex">x_i(t+1) = \Phi k_i(v) \quad \forall i \in [1,n]</script>, where <script type="math/tex">\Phi</script> is a regressor matrix consisting of <script type="math/tex">x</script> and <script type="math/tex">u</script>, and <script type="math/tex">k_i(v) \in \mathbf{R}^{n+m}</script> are the coefficients to be estimated for each <script type="math/tex">i</script>.</p>
<pre><code class="julia">using Plots, BasisFunctionExpansions
T          = 1000
x,xm,u,n,m = BasisFunctionExpansions.testdata(T)
nc         = 4
v          = 1:T
model      = LPVSS(x, u, v, nc; normalize=true, λ = 1e-3)
xh         = model(x,u,v)

eRMS       = √(mean((xh[1:end-1,:]-x[2:end,:]).^2))

plot(xh[1:end-1,:], lab=&quot;Prediction&quot;, c=:red, layout=(2,1))
plot!(x[2:end,:], lab=&quot;True&quot;, c=:blue); gui()
</code></pre>

<pre><code>/home/travis/.julia/v0.6/GR/src/../deps/gr/bin/gksqt: error while loading shared libraries: libQt5Widgets.so.5: cannot open shared object file: No such file or directory
connect: Connection refused
GKS: can't connect to GKS socket application
Did you start 'gksqt'?

GKS: Open failed in routine OPEN_WS
GKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine FILLAREA
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine FILLAREA
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine FILLAREA
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine TEXT
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
GKS: GKS not in proper state. GKS must be either in the state WSAC or SGOP in routine POLYLINE
</code></pre>

<p><img alt="window" src="./figs/lpvss.png" /></p>
<p><a id='Gradients-1'></a></p>
<h1 id="gradients">Gradients</h1>
<p>BasisFunctionExpansions plays nice with <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff.jl</a> and <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a></p>
<pre><code class="julia-repl">julia&gt; using ReverseDiff
julia&gt; a = randn(1,2)
julia&gt; ReverseDiff.gradient(bfa,a) # bfa here comes from the Multi-dim example
1×2 Array{Float64,2}:
 1.29364  -0.536586

julia&gt; h = 0.0001 # Finite difference for validation
0.0001

julia&gt; [(bfa(a+[h 0]) - bfa(a))/h (bfa(a+[0 h]) - bfa(a))/h]
1×2 Array{Float64,2}:
 1.29363  -0.536488
</code></pre>

<p>Note: for <code>ForwardDiff.jl</code> to work, you have to use <code>ForwardDiff.jacobian</code> instead of  <code>ForwardDiff.gradient</code>.</p>
<p>See <code>?ReverseDiff.gradient</code> for tips regarding high performance gradient calculation through preallocation of GradientConfig and prerecording of <code>bfa</code>.</p>
<p><a id='Learn-more-1'></a></p>
<h1 id="learn-more">Learn more</h1>
<p>Functionality in this package is used in the packages</p>
<ul>
<li><a href="https://github.com/baggepinnen/Robotlib.jl">Robotlib.jl</a></li>
<li><a href="https://github.com/baggepinnen/LPVSpectral.jl">LPVSpectral.jl</a></li>
<li><a href="https://github.com/baggepinnen/DynamicMovementPrimitives.jl">DynamicMovementPrimitives.jl</a></li>
</ul>
<p>And in the papers</p>
<ul>
<li><a href="http://lup.lub.lu.se/record/ac32368e-e199-44ff-b76a-36668ac7d595">"Linear Parameter-Varying Spectral Decomposition" Bagge Carlson, Fredrik; Robertsson, Anders and Johansson, Rolf (2017) American Control Conference Conference</a></li>
<li><a href="http://lup.lub.lu.se/record/7613758">"Modeling and Identification of Position and Temperature Dependent Friction Phenomena without Temperature Sensing" Bagge Carlson, Fredrik; Robertsson, Anders and Johansson, Rolf (2015) IEEE/RSJ International Conference on Intelligent Robots and Systems</a></li>
</ul>
<p><a id='Index-1'></a></p>
<h1 id="index">Index</h1>
<ul>
<li><a href=".#BasisFunctionExpansions.BasisFunctionApproximation"><code>BasisFunctionExpansions.BasisFunctionApproximation</code></a></li>
<li><a href=".#BasisFunctionExpansions.LPVSS-Tuple{Any,Any,Union{AbstractArray{T,1}, AbstractArray{T,2}} where T,Any}"><code>BasisFunctionExpansions.LPVSS</code></a></li>
<li><a href=".#BasisFunctionExpansions.LPVSS"><code>BasisFunctionExpansions.LPVSS</code></a></li>
<li><a href=".#BasisFunctionExpansions.LPVSS-Tuple{Any,Any,Any}"><code>BasisFunctionExpansions.LPVSS</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiDiagonalRBFE-Tuple{AbstractArray{T,2} where T,Any}"><code>BasisFunctionExpansions.MultiDiagonalRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiDiagonalRBFE-Union{Tuple{AbstractArray{T,2} where T,AbstractArray{T,1},Any}, Tuple{T}} where T&lt;:(AbstractArray{T,1} where T)"><code>BasisFunctionExpansions.MultiDiagonalRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiDiagonalRBFE"><code>BasisFunctionExpansions.MultiDiagonalRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiRBFE"><code>BasisFunctionExpansions.MultiRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiRBFE-Union{Tuple{AbstractArray{T,2} where T,AbstractArray{T,1},Any}, Tuple{T}} where T&lt;:(AbstractArray{T,1} where T)"><code>BasisFunctionExpansions.MultiRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiRBFE-Tuple{AbstractArray{T,2} where T,Any}"><code>BasisFunctionExpansions.MultiRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiUniformRBFE"><code>BasisFunctionExpansions.MultiUniformRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiUniformRBFE-Tuple{AbstractArray{T,2} where T,AbstractArray{T,1} where T,Any}"><code>BasisFunctionExpansions.MultiUniformRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.MultiUniformRBFE-Tuple{AbstractArray{T,2} where T,AbstractArray{Int64,1}}"><code>BasisFunctionExpansions.MultiUniformRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.UniformRBFE-Tuple{AbstractArray{T,1} where T,AbstractFloat,Any}"><code>BasisFunctionExpansions.UniformRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.UniformRBFE"><code>BasisFunctionExpansions.UniformRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.UniformRBFE-Tuple{AbstractArray{T,1} where T,Int64}"><code>BasisFunctionExpansions.UniformRBFE</code></a></li>
<li><a href=".#BasisFunctionExpansions.getARXregressor-Tuple{AbstractArray{T,1} where T,Union{AbstractArray{T,1}, AbstractArray{T,2}} where T,Any,Any}"><code>BasisFunctionExpansions.getARXregressor</code></a></li>
<li><a href=".#BasisFunctionExpansions.getARregressor-Tuple{AbstractArray{T,1} where T,Any}"><code>BasisFunctionExpansions.getARregressor</code></a></li>
<li><a href=".#BasisFunctionExpansions.get_centers"><code>BasisFunctionExpansions.get_centers</code></a></li>
<li><a href=".#BasisFunctionExpansions.get_centers_automatic"><code>BasisFunctionExpansions.get_centers_automatic</code></a></li>
<li><a href=".#BasisFunctionExpansions.get_centers_automatic"><code>BasisFunctionExpansions.get_centers_automatic</code></a></li>
<li><a href=".#BasisFunctionExpansions.output_variance"><code>BasisFunctionExpansions.output_variance</code></a></li>
<li><a href=".#BasisFunctionExpansions.predict"><code>BasisFunctionExpansions.predict</code></a></li>
<li><a href=".#BasisFunctionExpansions.predict-Tuple{BasisFunctionExpansions.LPVSS,AbstractArray{T,2} where T,Any}"><code>BasisFunctionExpansions.predict</code></a></li>
<li><a href=".#BasisFunctionExpansions.toeplitz-Union{Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N}, Tuple{T}} where T"><code>BasisFunctionExpansions.toeplitz</code></a></li>
</ul></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="./js/jquery-1.10.2.min.js"></script>
    <script src="./js/bootstrap-3.0.3.min.js"></script>
    <script src="./js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '.';
    </script>
    <script data-main="./mkdocs/js/search.js" src="./mkdocs/js/require.js"></script>
    <script src="./js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="./assets/mathjaxhelper.js"></script>
    <script src="./search/require.js"></script>
    <script src="./search/search.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>

<!--
MkDocs version : 0.17.3
Build Date UTC : 2018-05-29 09:03:20
-->
